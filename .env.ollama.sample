# Ollama API 配置
API_TYPE=ollama
API_URL=http://localhost:11434/api/generate
OLLAMA_MODEL=qwen3:30b-a3b

# 上下文长度配置 (tokens)
# 默认: 2048, 推荐: 4096-8192, 最大取决于模型支持
# 注意: 更大的上下文会消耗更多内存和计算时间
OLLAMA_CONTEXT_LENGTH=8192

# 最大输出长度配置 (tokens)
# 用于防止模型陷入无限循环，限制单次生成的最大token数
# 推荐: 2048-4096, 根据代码复杂度调整
OLLAMA_MAX_TOKENS=4096