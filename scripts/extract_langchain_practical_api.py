#!/usr/bin/env python3
"""
LangChainå®ç”¨APIæå–è„šæœ¬ - æå–å¯ç›´æ¥ä½¿ç”¨çš„ç±»å’Œæ–¹æ³•
"""

import sys
from pathlib import Path
import importlib
import inspect

# æ·»åŠ è™šæ‹Ÿç¯å¢ƒè·¯å¾„
venv_path = Path(__file__).parent.parent / ".venv"
site_packages = venv_path / "lib" / f"python{sys.version_info.major}.{sys.version_info.minor}" / "site-packages"
sys.path.insert(0, str(site_packages))

def get_practical_apis():
    """è·å–å®ç”¨çš„LangChain API"""
    
    practical_apis = {
        'LLMs': {
            'OpenAI': 'langchain.llms.OpenAI',
            'ChatOpenAI': 'langchain.chat_models.ChatOpenAI',
            'HuggingFaceHub': 'langchain.llms.HuggingFaceHub',
            'Ollama': 'langchain.llms.Ollama'
        },
        'Chains': {
            'LLMChain': 'langchain.chains.LLMChain',
            'RetrievalQA': 'langchain.chains.RetrievalQA',
            'ConversationalRetrievalChain': 'langchain.chains.ConversationalRetrievalChain'
        },
        'Prompts': {
            'PromptTemplate': 'langchain.prompts.PromptTemplate',
            'ChatPromptTemplate': 'langchain.prompts.ChatPromptTemplate',
            'FewShotPromptTemplate': 'langchain.prompts.FewShotPromptTemplate'
        },
        'VectorStores': {
            'Chroma': 'langchain.vectorstores.Chroma',
            'FAISS': 'langchain.vectorstores.FAISS',
            'Pinecone': 'langchain.vectorstores.Pinecone'
        },
        'Embeddings': {
            'OpenAIEmbeddings': 'langchain.embeddings.OpenAIEmbeddings',
            'HuggingFaceEmbeddings': 'langchain.embeddings.HuggingFaceEmbeddings',
            'OllamaEmbeddings': 'langchain.embeddings.OllamaEmbeddings'
        },
        'DocumentLoaders': {
            'TextLoader': 'langchain.document_loaders.TextLoader',
            'DirectoryLoader': 'langchain.document_loaders.DirectoryLoader',
            'PyPDFLoader': 'langchain.document_loaders.PyPDFLoader'
        },
        'TextSplitters': {
            'RecursiveCharacterTextSplitter': 'langchain.text_splitter.RecursiveCharacterTextSplitter',
            'CharacterTextSplitter': 'langchain.text_splitter.CharacterTextSplitter'
        },
        'Memory': {
            'ConversationBufferMemory': 'langchain.memory.ConversationBufferMemory',
            'ConversationBufferWindowMemory': 'langchain.memory.ConversationBufferWindowMemory'
        },
        'Agents': {
            'initialize_agent': 'langchain.agents.initialize_agent',
            'create_react_agent': 'langchain.agents.create_react_agent'
        },
        'Retrievers': {
            'VectorStoreRetriever': 'langchain.vectorstores.base.VectorStoreRetriever',
            'MultiQueryRetriever': 'langchain.retrievers.MultiQueryRetriever'
        }
    }
    
    extracted_apis = {}
    
    for category, items in practical_apis.items():
        extracted_apis[category] = {}
        
        for name, import_path in items.items():
            try:
                module_path, class_name = import_path.rsplit('.', 1)
                module = importlib.import_module(module_path)
                cls = getattr(module, class_name)
                
                # è·å–æ„é€ å‡½æ•°ç­¾å
                try:
                    sig = str(inspect.signature(cls.__init__))
                except:
                    sig = "()"
                
                # è·å–æ–‡æ¡£
                doc = inspect.getdoc(cls) or "æ— æ–‡æ¡£"
                
                extracted_apis[category][name] = {
                    'import_path': import_path,
                    'signature': sig,
                    'doc': doc,
                    'example': generate_example(category, name, import_path)
                }
                
                print(f"âœ… æå–äº† {category}.{name}")
                
            except Exception as e:
                print(f"âŒ æ— æ³•æå– {category}.{name}: {e}")
                extracted_apis[category][name] = {
                    'import_path': import_path,
                    'signature': "ä¸å¯ç”¨",
                    'doc': f"å¯¼å…¥é”™è¯¯: {e}",
                    'example': "# å¯¼å…¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¾èµ–"
                }
    
    return extracted_apis

def generate_example(category, name, import_path):
    """ç”Ÿæˆä½¿ç”¨ç¤ºä¾‹"""
    
    examples = {
        'LLMs': {
            'OpenAI': """from langchain.llms import OpenAI

llm = OpenAI(temperature=0.7)
response = llm("Hello, how are you?")""",
            'ChatOpenAI': """from langchain.chat_models import ChatOpenAI

chat = ChatOpenAI(model="gpt-3.5-turbo")
response = chat.invoke([{"role": "user", "content": "Hello!"}])"""
        },
        'Chains': {
            'LLMChain': """from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from langchain.llms import OpenAI

prompt = PromptTemplate(template="Say {adjective} to {name}!", input_variables=["adjective", "name"])
chain = LLMChain(llm=OpenAI(), prompt=prompt)
result = chain.run({"adjective": "hello", "name": "world"})""",
            'RetrievalQA': """from langchain.chains import RetrievalQA
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings

vectorstore = Chroma.from_texts(["Hello world"], OpenAIEmbeddings())
qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type="stuff", retriever=vectorstore.as_retriever())
result = qa.run("What is the text about?")"""
        },
        'Prompts': {
            'PromptTemplate': """from langchain.prompts import PromptTemplate

prompt = PromptTemplate(
    template="Tell me a {adjective} story about {topic}.",
    input_variables=["adjective", "topic"]
)"""
        },
        'VectorStores': {
            'Chroma': """from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings

# åˆ›å»ºå‘é‡å­˜å‚¨
vectorstore = Chroma.from_texts(
    ["Hello world", "Machine learning is fun"],
    OpenAIEmbeddings()
)

# ç›¸ä¼¼æ€§æœç´¢
results = vectorstore.similarity_search("hello", k=1)"""
        },
        'Embeddings': {
            'OpenAIEmbeddings': """from langchain.embeddings import OpenAIEmbeddings

embeddings = OpenAIEmbeddings()
text_embedding = embeddings.embed_query("Hello world")"""
        },
        'DocumentLoaders': {
            'TextLoader': """from langchain.document_loaders import TextLoader

loader = TextLoader("path/to/file.txt")
documents = loader.load()""",
            'DirectoryLoader': """from langchain.document_loaders import DirectoryLoader

loader = DirectoryLoader("path/to/directory", glob="**/*.txt")
documents = loader.load()"""
        },
        'TextSplitters': {
            'RecursiveCharacterTextSplitter': """from langchain.text_splitter import RecursiveCharacterTextSplitter

splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
texts = splitter.split_text("Your long text here...")"""
        },
        'Memory': {
            'ConversationBufferMemory': """from langchain.memory import ConversationBufferMemory

memory = ConversationBufferMemory()
memory.save_context({"input": "Hi"}, {"output": "Hello!"})
memory.load_memory_variables({})"""
        }
    }
    
    return examples.get(category, {}).get(name, f"# ä½¿ç”¨ {import_path}")

def generate_markdown(apis):
    """ç”Ÿæˆmarkdownæ–‡æ¡£"""
    
    md = """# LangChain å®ç”¨APIå‚è€ƒæ‰‹å†Œ

> è¿™ä»½æ–‡æ¡£åŒ…å«äº†LangChainæœ€å¸¸ç”¨çš„æ ¸å¿ƒAPIï¼Œå¯ä»¥ç›´æ¥å¤åˆ¶ä½¿ç”¨

## ğŸ“‹ ç›®å½•

"""
    
    for category in apis.keys():
        md += f"- [{category}](#{category.lower()})\n"
    
    for category, items in apis.items():
        md += f"\n## {category}\n\n"
        
        for name, info in items.items():
            md += f"### {name}\n"
            md += f"**å¯¼å…¥**: `from {info['import_path'].rsplit('.', 1)[0]} import {name}`\n\n"
            md += f"**æ„é€ å‡½æ•°**: `{name}{info['signature']}`\n\n"
            md += f"**è¯´æ˜**: {info['doc'][:200]}...\n\n"
            md += "**ä½¿ç”¨ç¤ºä¾‹**:\n```python\n"
            md += f"{info['example']}\n"
            md += "```\n\n"
            md += "---\n\n"
    
    return md

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” å¼€å§‹æå–LangChainå®ç”¨API...")
    
    apis = get_practical_apis()
    
    # ç”Ÿæˆmarkdown
    md_content = generate_markdown(apis)
    
    output_file = Path("knowledge_base/LANGCHAIN_PRACTICAL_API.md")
    output_file.parent.mkdir(exist_ok=True)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(md_content)
    
    print(f"âœ… å®ç”¨APIæ–‡æ¡£å·²ä¿å­˜åˆ°: {output_file}")
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_apis = sum(len(items) for items in apis.values())
    print(f"ğŸ“Š æ€»è®¡æå–äº† {total_apis} ä¸ªå®ç”¨API")

if __name__ == "__main__":
    main()