#!/usr/bin/env python3
"""
åŸºäºLLM+RAGçš„æµ‹è¯•ç”¨ä¾‹å¢å¼ºå™¨
ä½¿ç”¨å¤§æ¨¡å‹ç»“åˆRAGåˆ†ææµ‹è¯•ç”¨ä¾‹çš„descriptionå­—æ®µå¹¶æ™ºèƒ½é‡å†™
"""

import os
import sys
import json
import argparse
from pathlib import Path
from typing import Dict, List, Any, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from capl_langchain.config.config import CAPLGeneratorConfig
from capl_langchain.managers.knowledge_manager import KnowledgeManager
from capl_langchain.factories.llm_factory import LLMFactory


class TestcaseLLMEnhancer:
    """åŸºäºLLM+RAGçš„æµ‹è¯•ç”¨ä¾‹å¢å¼ºå™¨"""
    
    def __init__(self, config: CAPLGeneratorConfig):
        self.config = config
        self.knowledge_manager = KnowledgeManager(config)
        self.llm = LLMFactory.create_llm(config)
        
    def enhance_testcase(self, testcase_path: str) -> Dict[str, Any]:
        """å¢å¼ºå•ä¸ªæµ‹è¯•ç”¨ä¾‹"""
        print(f"ğŸš€ å¼€å§‹å¢å¼ºæµ‹è¯•ç”¨ä¾‹: {testcase_path}")
        
        # åˆå§‹åŒ–çŸ¥è¯†åº“
        if not self.knowledge_manager.initialize_knowledge_base():
            print("âŒ çŸ¥è¯†åº“åˆå§‹åŒ–å¤±è´¥")
            return {}
            
        # åŠ è½½æµ‹è¯•ç”¨ä¾‹
        with open(testcase_path, 'r', encoding='utf-8') as f:
            testcase = json.load(f)
            
        print("ğŸ” æ­£åœ¨åˆ†ææµ‹è¯•ç”¨ä¾‹ç»“æ„...")
        
        # å¢å¼ºæµ‹è¯•æ­¥éª¤æè¿°
        enhanced_testcase = self._enhance_with_llm(testcase)
        
        return enhanced_testcase
        
    def _enhance_with_llm(self, testcase: Dict[str, Any]) -> Dict[str, Any]:
        """ä½¿ç”¨LLMæ™ºèƒ½é‡å†™descriptionå­—æ®µ"""
        enhanced = testcase.copy()
        
        # å¢å¼ºæµ‹è¯•æ­¥éª¤æè¿°
        if 'steps' in testcase:
            enhanced_steps = []
            for i, step in enumerate(testcase['steps']):
                enhanced_step = step.copy()
                if 'description' in step and 'test_step' in step:
                    print(f"ğŸ¤– æ­£åœ¨å¤„ç†ç¬¬ {i+1} ä¸ªæ­¥éª¤: {step['test_step']}")
                    
                    # è·å–ç›¸å…³ä¸Šä¸‹æ–‡
                    context = self._get_relevant_context(step)
                    
                    # ä½¿ç”¨LLMé‡å†™æè¿°
                    enhanced_description = self._rewrite_description_with_llm(
                        step['description'],
                        step['test_step'],
                        context
                    )
                    enhanced_step['description'] = enhanced_description
                    enhanced_step['original_description'] = step['description']
                    
                    # æ·»åŠ å¤„ç†æ ‡è®°
                    enhanced_step['enhanced_by'] = f"llm_{self.config.api_type}"
                    
                enhanced_steps.append(enhanced_step)
            enhanced['steps'] = enhanced_steps
            
        return enhanced
        
    def _get_relevant_context(self, step: Dict) -> str:
        """è·å–ç›¸å…³çš„æŠ€æœ¯ä¸Šä¸‹æ–‡"""
        query = f"{step['test_step']} - {step['description']}"
        
        # æœç´¢ç›¸å…³çŸ¥è¯†
        relevant_docs = self.knowledge_manager.search_documents(
            query=query,
            k=3,
            enable_rerank=True
        )
        
        if not relevant_docs:
            return ""
            
        context_parts = []
        for doc in relevant_docs:
            context_parts.append(f"ç›¸å…³æŠ€æœ¯æ–‡æ¡£: {doc['source']}")
            context_parts.append(f"å†…å®¹æ‘˜è¦: {doc['summary']}")
            context_parts.append("")
            
        return "\n".join(context_parts)
        
    def _rewrite_description_with_llm(self, original_desc: str, test_step: str, context: str) -> str:
        """ä½¿ç”¨LLMé‡å†™æè¿°"""
        
        prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ±½è½¦æµ‹è¯•å·¥ç¨‹å¸ˆï¼Œè´Ÿè´£å¢å¼ºæµ‹è¯•ç”¨ä¾‹çš„æè¿°ã€‚

åŸå§‹æµ‹è¯•æ­¥éª¤: {test_step}
åŸå§‹æè¿°: {original_desc}

ç›¸å…³æŠ€æœ¯ä¸Šä¸‹æ–‡:
{context}

è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œç”¨æ›´ä¸“ä¸šã€è¯¦ç»†çš„æ–¹å¼é‡å†™è¿™ä¸ªæµ‹è¯•æ­¥éª¤çš„æè¿°ã€‚
è¦æ±‚ï¼š
1. ä¿æŒæŠ€æœ¯å‡†ç¡®æ€§
2. æ·»åŠ å…·ä½“çš„æµ‹è¯•ç›®çš„å’Œé¢„æœŸç»“æœ
3. åŒ…å«ç›¸å…³çš„APIæˆ–å‡½æ•°è°ƒç”¨ä¿¡æ¯
4. ä½¿ç”¨æ¸…æ™°çš„æµ‹è¯•è¯­è¨€
5. ä¸è¶…è¿‡200å­—

é‡å†™åçš„æè¿°:"""

        try:
            response = self.llm.invoke(prompt)
            enhanced_desc = response.content if hasattr(response, 'content') else str(response)
            
            # æ¸…ç†å“åº”
            enhanced_desc = enhanced_desc.strip()
            if enhanced_desc.startswith('"') and enhanced_desc.endswith('"'):
                enhanced_desc = enhanced_desc[1:-1]
                
            return enhanced_desc or original_desc
            
        except Exception as e:
            print(f"âš ï¸ LLMå¤„ç†å¤±è´¥: {e}")
            return original_desc
            
    def save_enhanced_testcase(self, enhanced_testcase: Dict[str, Any], output_path: str):
        """ä¿å­˜å¢å¼ºåçš„æµ‹è¯•ç”¨ä¾‹"""
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(enhanced_testcase, f, ensure_ascii=False, indent=2)
        print(f"âœ… å¢å¼ºåçš„æµ‹è¯•ç”¨ä¾‹å·²ä¿å­˜: {output_path}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="åŸºäºLLM+RAGçš„æµ‹è¯•ç”¨ä¾‹å¢å¼ºå™¨")
    parser.add_argument("testcase_path", help="æµ‹è¯•ç”¨ä¾‹æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--model", choices=["openai", "ollama"], default="ollama", 
                       help="ä½¿ç”¨çš„æ¨¡å‹ç±»å‹")
    parser.add_argument("--suffix", default=".llm_enhanced", 
                       help="è¾“å‡ºæ–‡ä»¶åç¼€")
    
    args = parser.parse_args()
    
    # åˆ›å»ºé…ç½®
    config = CAPLGeneratorConfig()
    config.api_type = args.model
    config.enable_rag = True
    config.use_hybrid_search = False
    config.knowledge_base_dir = project_root / "knowledge_base"
    config.vector_db_dir = project_root / "vector_db"
    
    # è®¾ç½®ä½¿ç”¨å°æ¨¡å‹qwen3:1.7b
    config.model = "qwen3:1.7b"
    
    # åˆ›å»ºå¢å¼ºå™¨
    enhancer = TestcaseLLMEnhancer(config)
    
    # å¢å¼ºæµ‹è¯•ç”¨ä¾‹
    enhanced = enhancer.enhance_testcase(args.testcase_path)
    
    if enhanced:
        # ç”Ÿæˆè¾“å‡ºè·¯å¾„
        input_path = Path(args.testcase_path)
        output_path = input_path.with_suffix(f"{input_path.suffix}{args.suffix}")
        
        # ä¿å­˜ç»“æœ
        enhancer.save_enhanced_testcase(enhanced, str(output_path))
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        total_steps = len(enhanced.get('steps', []))
        enhanced_steps = sum(1 for step in enhanced.get('steps', []) 
                           if 'enhanced_by' in step)
        
        print(f"\nğŸ“Š å¢å¼ºå®Œæˆç»Ÿè®¡:")
        print(f"   âœ… æ€»æ­¥éª¤æ•°: {total_steps}")
        print(f"   âœ… å·²å¢å¼ºæ­¥éª¤: {enhanced_steps}")
        print(f"   âœ… å¢å¼ºæ¯”ä¾‹: {enhanced_steps/total_steps*100:.1f}%")
    else:
        print("âŒ å¢å¼ºå¤±è´¥")


if __name__ == "__main__":
    main()