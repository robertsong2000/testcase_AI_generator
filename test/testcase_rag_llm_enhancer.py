#!/usr/bin/env python3
"""
åŸºäºLLM+RAGçš„æµ‹è¯•ç”¨ä¾‹å¢å¼ºå™¨
ä½¿ç”¨å¤§æ¨¡å‹ç»“åˆRAGåˆ†ææµ‹è¯•ç”¨ä¾‹çš„descriptionå­—æ®µå¹¶æ™ºèƒ½é‡å†™
"""

import os
import sys
import json
import argparse
from pathlib import Path
from typing import Dict, List, Any, Optional

import copy  # æ·»åŠ copyæ¨¡å—å¯¼å…¥

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from capl_langchain.config.config import CAPLGeneratorConfig
from capl_langchain.managers.knowledge_manager import KnowledgeManager
from capl_langchain.factories.llm_factory import LLMFactory

class TestcaseLLMEnhancer:
    """åŸºäºLLM+RAGçš„æµ‹è¯•ç”¨ä¾‹å¢å¼ºå™¨"""
    
    def __init__(self, config: CAPLGeneratorConfig, verbose: bool = False):
        self.config = config
        self.knowledge_manager = KnowledgeManager(config)
        self.llm = LLMFactory.create_llm(config)
        self.verbose = verbose
        self._testcase_purpose_cache = {}  # ç¼“å­˜æµ‹è¯•ç”¨ä¾‹ç›®çš„
        
    def _get_cached_purpose(self, testcase: Dict[str, Any]) -> str:
        """è·å–ç¼“å­˜çš„æµ‹è¯•ç”¨ä¾‹ç›®çš„ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ†æå¹¶ç¼“å­˜"""
        # ä½¿ç”¨æµ‹è¯•ç”¨ä¾‹IDä½œä¸ºç¼“å­˜é”®
        cache_key = testcase.get('id', testcase.get('name', str(hash(str(testcase)))))
        
        if cache_key not in self._testcase_purpose_cache:
            if self.verbose:
                print(f"ğŸ” é¦–æ¬¡åˆ†ææµ‹è¯•ç”¨ä¾‹ç›®çš„: {testcase.get('title', cache_key)}")
            self._testcase_purpose_cache[cache_key] = self._analyze_testcase_purpose(testcase)
               
        return self._testcase_purpose_cache[cache_key]
        
    def enhance_testcase(self, testcase_path: str, step_index: Optional[int] = None) -> Dict[str, Any]:
        """å¢å¼ºå•ä¸ªæµ‹è¯•ç”¨ä¾‹"""
        print(f"ğŸš€ å¼€å§‹å¢å¼ºæµ‹è¯•ç”¨ä¾‹: {testcase_path}")
        
        if step_index is not None:
            print(f"ğŸ“ æŒ‡å®šå¤„ç†æ­¥éª¤: ç¬¬ {step_index + 1} æ­¥")
        
        # åˆå§‹åŒ–çŸ¥è¯†åº“
        if not self.knowledge_manager.initialize_knowledge_base():
            print("âŒ çŸ¥è¯†åº“åˆå§‹åŒ–å¤±è´¥")
            return {}
            
        # åŠ è½½æµ‹è¯•ç”¨ä¾‹
        with open(testcase_path, 'r', encoding='utf-8') as f:
            testcase = json.load(f)
            
        print("ğŸ” æ­£åœ¨åˆ†ææµ‹è¯•ç”¨ä¾‹ç»“æ„...")
        
        # å¢å¼ºæµ‹è¯•æ­¥éª¤æè¿°
        enhanced_testcase = self._enhance_with_llm(testcase, step_index)
        
        return enhanced_testcase
        
    def _enhance_with_llm(self, testcase: Dict[str, Any], step_index: Optional[int] = None) -> Dict[str, Any]:
        """ä½¿ç”¨LLMå¢å¼ºæµ‹è¯•ç”¨ä¾‹æè¿°"""
        
        # è·å–æµ‹è¯•ç”¨ä¾‹çš„æ•´ä½“ç›®çš„ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
        overall_purpose = self._get_cached_purpose(testcase)
        
        # åˆ›å»ºæµ‹è¯•ç”¨ä¾‹çš„æ·±æ‹·è´ä»¥é¿å…ä¿®æ”¹åŸå§‹æ•°æ®
        enhanced_testcase = copy.deepcopy(testcase)
        
        # ç¡®å®šè¦å¤„ç†çš„æ­¥éª¤èŒƒå›´
        steps_to_process = []
        if step_index is not None:
            if 0 <= step_index < len(enhanced_testcase['steps']):
                steps_to_process = [(step_index, enhanced_testcase['steps'][step_index])]
            else:
                print(f"âš ï¸ æ­¥éª¤ç´¢å¼• {step_index} è¶…å‡ºèŒƒå›´ï¼Œå¤„ç†æ‰€æœ‰æ­¥éª¤")
                steps_to_process = list(enumerate(enhanced_testcase['steps']))
        else:
            steps_to_process = list(enumerate(enhanced_testcase['steps']))
        
        # å¤„ç†æ¯ä¸ªæ­¥éª¤
        for i, step in steps_to_process:
            print(f"\nğŸ“‹ å¤„ç†æ­¥éª¤ {i+1}/{len(enhanced_testcase['steps'])}")
            if self.verbose:
                print(f"   åŸå§‹æè¿°: {step.get('description', 'æ— æè¿°')}")
            
            # è·å–å¢å¼ºçš„ä¸Šä¸‹æ–‡
            enhanced_context = self._get_enhanced_context(step, enhanced_testcase, i, overall_purpose)
            
            # ä½¿ç”¨LLMé‡å†™æè¿°
            enhanced_description = self._rewrite_description_with_llm(
                step, enhanced_context, overall_purpose, i, len(enhanced_testcase['steps'])
            )
            
            # ä¿å­˜åŸå§‹æè¿°å¹¶æ›´æ–°
            if 'original_description' not in step:
                step['original_description'] = step.get('description', '')
            step['description'] = enhanced_description
            
            if self.verbose:
                print(f"   å¢å¼ºæè¿°: {enhanced_description}...")
        
        return enhanced_testcase
        
    def _get_relevant_context(self, step: Dict) -> str:
        """è·å–ç›¸å…³çš„æŠ€æœ¯ä¸Šä¸‹æ–‡"""
        query = f"{step['test_step']} - {step['description']}"
        
        # æœç´¢ç›¸å…³çŸ¥è¯†
        relevant_docs = self.knowledge_manager.search_documents(
            query=query,
            k=3,
            enable_rerank=True
        )
        
        if not relevant_docs:
            return ""
            
        context_parts = []
        for doc in relevant_docs:
            context_parts.append(f"ç›¸å…³æŠ€æœ¯æ–‡æ¡£: {doc['source']}")
            context_parts.append(f"å†…å®¹æ‘˜è¦: {doc['summary']}")
            context_parts.append("")
            
        return "\n".join(context_parts)
        
    def _rewrite_description_with_llm(self, step: Dict, context: str, overall_purpose: str, step_index: int, total_steps: int) -> str:
        """ä½¿ç”¨LLMé‡å†™æ­¥éª¤æè¿°"""
        
        original_desc = step.get('description', '')
        test_step = step.get('test_step', '')
        
        prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ±½è½¦ç”µå­æµ‹è¯•å·¥ç¨‹å¸ˆï¼Œè¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ä¿¡æ¯é‡å†™æµ‹è¯•æ­¥éª¤çš„æè¿°ã€‚

**ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š**
{context}

**éœ€è¦é‡å†™çš„æµ‹è¯•æ­¥éª¤ï¼š**
- æ­¥éª¤åç§°: {test_step}
- åŸå§‹æè¿°: {original_desc}

**é‡å†™è¦æ±‚ï¼š**
1. **ç†è§£æ•´ä½“ç›®çš„**: åŸºäºä¸Šä¸‹æ–‡ä¿¡æ¯çš„æ•´ä½“æµ‹è¯•ç”¨ä¾‹ç›®çš„ï¼Œæ˜ç¡®æ­¤æ­¥éª¤åœ¨æµç¨‹ä¸­çš„ä½œç”¨
2. **ä¿æŒæŠ€æœ¯å‡†ç¡®æ€§**: ç¡®ä¿æè¿°ç¬¦åˆæ±½è½¦ç”µå­æµ‹è¯•æ ‡å‡†
3. **æ·»åŠ å…·ä½“ç»†èŠ‚**: åŒ…å«å…·ä½“çš„æµ‹è¯•ç›®çš„ã€é¢„æœŸç»“æœå’ŒéªŒè¯æ–¹æ³•
4. **æ­¥éª¤å…³è”æ€§**: è€ƒè™‘ä¸å‰åæ­¥éª¤çš„è¡”æ¥å…³ç³»
5. **APIè§„èŒƒ**: åŒ…å«ç›¸å…³çš„APIæˆ–å‡½æ•°è°ƒç”¨ä¿¡æ¯ï¼Œä½†å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹è§„åˆ™ï¼š
   - åªèƒ½ä½¿ç”¨çŸ¥è¯†åº“ä¸­æä¾›çš„APIæ ¼å¼
   - å¦‚æœAPIæ˜¯æ— å‚å‡½æ•°ï¼Œä¸èƒ½æ·»åŠ ä»»ä½•å‚æ•°
   - å¦‚æœAPIæœ‰å‚æ•°ï¼Œå¿…é¡»ä½¿ç”¨æ­£ç¡®çš„å‚æ•°ç±»å‹å’Œæ•°é‡
   - ä¸èƒ½ç¼–é€ ä¸å­˜åœ¨çš„APIæˆ–å‚æ•°
6. **è¯­è¨€è§„èŒƒ**: ä½¿ç”¨æ¸…æ™°çš„æµ‹è¯•è¯­è¨€ï¼Œä¸è¶…è¿‡200å­—

**é‡å†™åçš„æè¿°:**"""

        try:
            if self.verbose:
                print(f"ğŸ“ å‘é€ç»™LLMçš„æç¤ºè¯: {prompt}")
            response = self.llm.invoke(prompt)
            enhanced_desc = response.content if hasattr(response, 'content') else str(response)
            
            # æ¸…ç†å“åº”
            import re
            enhanced_desc = enhanced_desc.strip()
            enhanced_desc = re.sub(r'<think>.*?</think>', '', enhanced_desc, flags=re.DOTALL)
            enhanced_desc = re.sub(r'</?think>', '', enhanced_desc)
            enhanced_desc = re.sub(r'\n\s*\n', ' ', enhanced_desc)
            enhanced_desc = enhanced_desc.strip()
                       
            return enhanced_desc if enhanced_desc else original_desc
            
        except Exception as e:
            print(f"âš ï¸ LLMé‡å†™æè¿°å¤±è´¥: {e}")
            return original_desc
            
    def save_enhanced_testcase(self, enhanced_testcase: Dict[str, Any], output_path: str):
        """ä¿å­˜å¢å¼ºåçš„æµ‹è¯•ç”¨ä¾‹"""
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(enhanced_testcase, f, ensure_ascii=False, indent=2)
        print(f"âœ… å¢å¼ºåçš„æµ‹è¯•ç”¨ä¾‹å·²ä¿å­˜: {output_path}")

    def _analyze_testcase_purpose(self, testcase: Dict[str, Any]) -> str:
        """ä½¿ç”¨å¤§æ¨¡å‹æ™ºèƒ½åˆ†ææµ‹è¯•ç”¨ä¾‹çš„æ•´ä½“ç›®çš„"""
        
        # æ„å»ºæµ‹è¯•ç”¨ä¾‹çš„å®Œæ•´æè¿°
        testcase_info = []
        
        # æµ‹è¯•ç”¨ä¾‹åŸºæœ¬ä¿¡æ¯
        if 'title' in testcase:
            testcase_info.append(f"æµ‹è¯•ç”¨ä¾‹æ ‡é¢˜: {testcase['title']}")
            
        if 'name' in testcase:
            testcase_info.append(f"æµ‹è¯•ç”¨ä¾‹åç§°: {testcase['name']}")
            
        # å‰ç½®æ¡ä»¶
        if 'preconditions' in testcase:
            preconditions = testcase['preconditions']
            if isinstance(preconditions, list):
                preconditions = '\n'.join(str(p) for p in preconditions if p)
            testcase_info.append(f"å‰ç½®æ¡ä»¶:\n{preconditions}")
            
        # æµ‹è¯•æ­¥éª¤
        if 'steps' in testcase and testcase['steps']:
            steps_info = []
            for i, step in enumerate(testcase['steps'], 1):
                step_desc = f"æ­¥éª¤{i}: {step.get('test_step', 'æœªå‘½åæ­¥éª¤')}"
                if 'description' in step:
                    step_desc += f" - {step['description'][:100]}..."
                steps_info.append(step_desc)
            testcase_info.append(f"æµ‹è¯•æ­¥éª¤:\n" + '\n'.join(steps_info))
            
        # é¢„æœŸç»“æœ
        if 'expected_results' in testcase:
            expected = testcase['expected_results']
            if isinstance(expected, list):
                expected = '\n'.join(str(e) for e in expected)
            testcase_info.append(f"é¢„æœŸç»“æœ:\n{expected}")
            
        # å¦‚æœæ²¡æœ‰è¶³å¤Ÿä¿¡æ¯ï¼Œè¿”å›ç®€åŒ–åˆ†æ
        if not testcase_info:
            title = testcase.get('title', testcase.get('name', 'æœªçŸ¥æµ‹è¯•'))
            return f"æµ‹è¯•åŠŸèƒ½: {title}"
            
        full_context = '\n\n'.join(testcase_info)
        
        # ä½¿ç”¨å¤§æ¨¡å‹åˆ†ææµ‹è¯•ç›®çš„
        purpose_prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ±½è½¦æµ‹è¯•å·¥ç¨‹å¸ˆï¼Œè¯·åˆ†æä»¥ä¸‹æµ‹è¯•ç”¨ä¾‹å¹¶æç‚¼å…¶æ ¸å¿ƒæµ‹è¯•ç›®çš„ã€‚

è¯·åŸºäºæµ‹è¯•ç”¨ä¾‹çš„å®Œæ•´ä¿¡æ¯ï¼Œç”¨ç®€æ´çš„è¯­è¨€æ€»ç»“è¿™ä¸ªæµ‹è¯•ç”¨ä¾‹çš„æ ¸å¿ƒæµ‹è¯•ç›®çš„å’Œä¸»è¦éªŒè¯ç‚¹ã€‚

è¦æ±‚ï¼š
1. ç”¨ä¸€å¥è¯æ¦‚æ‹¬æµ‹è¯•çš„æ ¸å¿ƒç›®çš„
2. çªå‡ºæµ‹è¯•çš„ä¸»è¦åŠŸèƒ½å’ŒéªŒè¯ç›®æ ‡
3. è¯­è¨€ç®€æ´ä¸“ä¸šï¼Œä¸è¶…è¿‡200å­—
4. é¿å…å†—ä½™çš„æè¿°æ€§è¯æ±‡

æµ‹è¯•ç”¨ä¾‹ä¿¡æ¯ï¼š
{full_context}

æµ‹è¯•ç›®çš„æ€»ç»“:"""

        try:
            response = self.llm.invoke(purpose_prompt)
            purpose = response.content if hasattr(response, 'content') else str(response)
            
            # æ¸…ç†å“åº”
            import re
            purpose = purpose.strip()
            purpose = re.sub(r'<think>.*?</think>', '', purpose, flags=re.DOTALL)
            purpose = re.sub(r'</?think>', '', purpose)
            purpose = re.sub(r'\n\s*\n', ' ', purpose)
            purpose = purpose.strip()
                
            # å¦‚æœå¤§æ¨¡å‹è¿”å›ç©ºæˆ–æ— æ•ˆï¼Œä½¿ç”¨æ ‡é¢˜å…œåº•
            if not purpose or len(purpose.strip()) < 5:
                title = testcase.get('title', testcase.get('name', 'æœªçŸ¥æµ‹è¯•'))
                title = title.replace('TC_', '').replace('_', ' ')
                return f"æµ‹è¯•: {title}"
                
            return purpose
            
        except Exception as e:
            print(f"âš ï¸ å¤§æ¨¡å‹åˆ†ææµ‹è¯•ç›®çš„å¤±è´¥: {e}")
            # å›é€€åˆ°æ ‡é¢˜
            title = testcase.get('title', testcase.get('name', 'æœªçŸ¥æµ‹è¯•'))
            title = title.replace('TC_', '').replace('_', ' ')
            return f"æµ‹è¯•: {title}"
        
    def _get_enhanced_context(self, step: Dict, testcase: Dict, step_index: int, overall_purpose: str) -> str:
        """æ„å»ºåŒ…å«æ•´ä½“æµ‹è¯•ç›®çš„çš„å¢å¼ºä¸Šä¸‹æ–‡"""
        
        # è·å–æŠ€æœ¯ä¸Šä¸‹æ–‡
        technical_context = self._get_relevant_context(step)
        
        # æ„å»ºæ­¥éª¤ä¸Šä¸‹æ–‡ä¿¡æ¯
        context_parts = []
        
        # 1. æ•´ä½“æµ‹è¯•ç›®çš„ï¼ˆå·²ç¼“å­˜ï¼‰
        context_parts.append(f"æµ‹è¯•ç”¨ä¾‹æ•´ä½“ç›®çš„: {overall_purpose}")
        
        # 2. å½“å‰æ­¥éª¤ä½ç½®ä¿¡æ¯
        total_steps = len(testcase['steps'])
        context_parts.append(f"å½“å‰æ­¥éª¤: ç¬¬ {step_index + 1} æ­¥ (å…± {total_steps} æ­¥)")
        
        # 3. å‰åæ­¥éª¤å…³è”ï¼ˆå¦‚æœæœ‰ï¼‰
        if step_index > 0:
            prev_step = testcase['steps'][step_index - 1]
            context_parts.append(f"ä¸Šä¸€æ­¥éª¤: {prev_step.get('test_step', 'æœªçŸ¥')}")
        
        if step_index < total_steps - 1:
            next_step = testcase['steps'][step_index + 1]
            context_parts.append(f"ä¸‹ä¸€æ­¥éª¤: {next_step.get('test_step', 'æœªçŸ¥')}")
        
        # 4. æŠ€æœ¯ä¸Šä¸‹æ–‡
        if technical_context:
            context_parts.append(f"æŠ€æœ¯ä¸Šä¸‹æ–‡: {technical_context}")
        
        return "\n".join(context_parts)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="åŸºäºLLM+RAGçš„æµ‹è¯•ç”¨ä¾‹å¢å¼ºå™¨")
    parser.add_argument("testcase_path", help="æµ‹è¯•ç”¨ä¾‹æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--model", choices=["openai", "ollama"], default="ollama", 
                       help="ä½¿ç”¨çš„æ¨¡å‹ç±»å‹")
    parser.add_argument("--suffix", default=".llm_enhanced", 
                       help="è¾“å‡ºæ–‡ä»¶åç¼€")
    parser.add_argument("--verbose", action="store_true", 
                       help="æ˜¾ç¤ºè¯¦ç»†çš„å¤„ç†è¿‡ç¨‹ä¿¡æ¯")
    parser.add_argument("--step-index", type=int, 
                       help="æŒ‡å®šè¦å¤„ç†çš„æ­¥éª¤ç´¢å¼•ï¼ˆä»0å¼€å§‹ï¼‰ï¼Œä¸æŒ‡å®šåˆ™å¤„ç†æ‰€æœ‰æ­¥éª¤")
    
    args = parser.parse_args()
    
    # åˆ›å»ºé…ç½®
    config = CAPLGeneratorConfig()
    config.api_type = args.model
    config.enable_rag = True
    config.use_hybrid_search = True
    config.knowledge_base_dir = project_root / "knowledge_base"
    config.vector_db_dir = project_root / "vector_db"
    
    # è®¾ç½®ä½¿ç”¨å°æ¨¡å‹qwen3:1.7b
    config.model = "qwen3:1.7b"
    
    # åˆ›å»ºå¢å¼ºå™¨ï¼ˆä¼ å…¥verboseå‚æ•°ï¼‰
    enhancer = TestcaseLLMEnhancer(config, verbose=args.verbose)
    
    if args.verbose:
        print(f"ğŸ”§ è¯¦ç»†æ¨¡å¼å·²å¼€å¯")
        print(f"   ä½¿ç”¨æ¨¡å‹: {config.model}")
        print(f"   çŸ¥è¯†åº“ç›®å½•: {config.knowledge_base_dir}")
        print(f"   å‘é‡æ•°æ®åº“ç›®å½•: {config.vector_db_dir}")
        if args.step_index is not None:
            print(f"   æŒ‡å®šæ­¥éª¤ç´¢å¼•: {args.step_index}")
        print()
    
    # å¢å¼ºæµ‹è¯•ç”¨ä¾‹
    enhanced = enhancer.enhance_testcase(args.testcase_path, args.step_index)
    
    if enhanced:
        # ç”Ÿæˆè¾“å‡ºè·¯å¾„
        input_path = Path(args.testcase_path)
        
        # å¦‚æœæŒ‡å®šäº†æ­¥éª¤ç´¢å¼•ï¼Œä¿®æ”¹åç¼€ä»¥åŒºåˆ†
        if args.step_index is not None:
            suffix = f"{args.suffix}_step_{args.step_index}"
        else:
            suffix = args.suffix
            
        output_path = input_path.with_suffix(f"{input_path.suffix}{suffix}")
        
        # ä¿å­˜ç»“æœ
        enhancer.save_enhanced_testcase(enhanced, str(output_path))
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        total_steps = len(enhanced.get('steps', []))
        
        if args.step_index is not None:
            print(f"\nğŸ“Š å¢å¼ºå®Œæˆç»Ÿè®¡:")
            print(f"   âœ… æ€»æ­¥éª¤æ•°: {total_steps}")
            print(f"   âœ… å·²å¤„ç†æ­¥éª¤: ç¬¬ {args.step_index + 1} æ­¥")
        else:
            enhanced_steps = sum(1 for step in enhanced.get('steps', []) 
                               if 'enhanced_by' in step)
            print(f"\nğŸ“Š å¢å¼ºå®Œæˆç»Ÿè®¡:")
            print(f"   âœ… æ€»æ­¥éª¤æ•°: {total_steps}")
            print(f"   âœ… å·²å¢å¼ºæ­¥éª¤: {enhanced_steps}")
            print(f"   âœ… å¢å¼ºæ¯”ä¾‹: {enhanced_steps/total_steps*100:.1f}%")
        
        if args.verbose:
            print(f"   ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_path}")
    else:
        print("âŒ å¢å¼ºå¤±è´¥")


if __name__ == "__main__":
    main()