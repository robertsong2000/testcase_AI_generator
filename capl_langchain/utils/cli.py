"""å‘½ä»¤è¡Œæ¥å£å·¥å…·"""

import argparse
import sys
from pathlib import Path

from ..generator import CAPLGenerator
from ..config.config import CAPLGeneratorConfig


def create_parser() -> argparse.ArgumentParser:
    """åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨"""
    parser = argparse.ArgumentParser(
        description="CAPLä»£ç ç”Ÿæˆå™¨ - åŸºäºLangChainçš„AIé©±åŠ¨CAPLè„šæœ¬ç”Ÿæˆå·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  %(prog)s requirements.txt                          # é»˜è®¤æµå¼è¾“å‡º
  %(prog)s requirements.txt --no-stream            # ç¦ç”¨æµå¼è¾“å‡º
  %(prog)s requirements.txt --output ./generated/
  %(prog)s requirements.txt --disable-rag
  %(prog)s requirements.txt -k 8                   # è®¾ç½®RAGæ£€ç´¢è¿”å›8ä¸ªæ–‡æ¡£
  %(prog)s --info
  %(prog)s --search "CAPL message handling"
  %(prog)s --test-rag "message filter"
  %(prog)s requirements.txt --debug-prompt
  %(prog)s requirements.txt --rebuild-rag
  %(prog)s requirements.txt --no-use-example-code  # ç¦ç”¨ç¤ºä¾‹ä»£ç 
  %(prog)s requirements.txt --use-example-code     # å¼ºåˆ¶ä½¿ç”¨ç¤ºä¾‹ä»£ç 
  %(prog)s requirements.txt --chunk-size 600       # å¹³è¡¡åœºæ™¯é…ç½®
  %(prog)s requirements.txt --chunk-overlap 100    # å¹³è¡¡åœºæ™¯é…ç½®
  %(prog)s requirements.txt --chunk-size 800 --chunk-overlap 150  # å®Œæ•´ä¸Šä¸‹æ–‡é…ç½®
        """
    )
    
    # è¾“å…¥å‚æ•°ï¼ˆå¯é€‰ï¼‰
    parser.add_argument(
        'input', 
        nargs='?',
        help='è¾“å…¥éœ€æ±‚æ–‡ä»¶è·¯å¾„æˆ–ç›´æ¥è¾“å…¥éœ€æ±‚æ–‡æœ¬'
    )
    
    # è¾“å‡ºé…ç½®
    parser.add_argument(
        '--output', '-o',
        type=str,
        default='./generated',
        help='è¾“å‡ºç›®å½•è·¯å¾„ (é»˜è®¤: ./generated)'
    )
    
    # LLMé…ç½®
    parser.add_argument(
        '--api-type',
        type=str,
        default='ollama',
        choices=['ollama', 'openai'],
        help='APIç±»å‹ (ollama/openai)'
    )
    
    parser.add_argument(
        '--api-url',
        type=str,
        help='APIåŸºç¡€URL (ç”¨äºè‡ªå®šä¹‰æˆ–æœ¬åœ°API)'
    )
    
    parser.add_argument(
        '--model',
        type=str,
        help='ä½¿ç”¨çš„æ¨¡å‹åç§°'
    )
    
    # RAGé…ç½®
    parser.add_argument(
        '--disable-rag',
        action='store_true',
        help='ç¦ç”¨RAGåŠŸèƒ½'
    )
    
    parser.add_argument(
        '-k', '--k',
        type=int,
        default=8,
        metavar='K',
        help='RAGæ£€ç´¢è¿”å›çš„æ–‡æ¡£æ•°é‡ (é»˜è®¤: 8)'
    )
    
    parser.add_argument(
        '--chunk-size',
        type=int,
        default=400,
        metavar='SIZE',
        help='æ–‡æ¡£åˆ†å—å¤§å°ï¼Œå•ä½å­—ç¬¦ (é»˜è®¤: 400 - é«˜ç²¾åº¦åœºæ™¯)'
    )
    
    parser.add_argument(
        '--chunk-overlap',
        type=int,
        default=50,
        metavar='OVERLAP',
        help='æ–‡æ¡£åˆ†å—é‡å å¤§å°ï¼Œå•ä½å­—ç¬¦ (é»˜è®¤: 50 - é«˜ç²¾åº¦åœºæ™¯)'
    )
    
    parser.add_argument(
        '--rebuild-rag',
        action='store_true',
        help='å¼ºåˆ¶é‡å»ºRAGçŸ¥è¯†åº“'
    )
    
    # è°ƒè¯•å’Œæµ‹è¯•
    parser.add_argument(
        '--debug-prompt',
        action='store_true',
        help='æ˜¾ç¤ºå®Œæ•´çš„promptå†…å®¹ï¼ˆè°ƒè¯•ç”¨ï¼‰'
    )
    
    parser.add_argument(
        '--test-rag',
        type=str,
        metavar='QUERY',
        help='æµ‹è¯•RAGæœç´¢åŠŸèƒ½'
    )
    
    # ç¤ºä¾‹ä»£ç é…ç½®
    parser.add_argument(
        '--use-example-code',
        action='store_true',
        default=True,
        help='å¼ºåˆ¶ä½¿ç”¨ç¤ºä¾‹CAPLä»£ç ï¼Œæ— è®ºRAGæ˜¯å¦å¯ç”¨ (é»˜è®¤: å¼€å¯)'
    )
    
    parser.add_argument(
        '--no-use-example-code',
        action='store_false',
        dest='use_example_code',
        help='ç¦ç”¨ç¤ºä¾‹CAPLä»£ç ï¼Œä»…åŸºäºéœ€æ±‚ç”Ÿæˆ'
    )
    
    parser.add_argument(
        '--no-force-example',
        action='store_false',
        dest='force_example',
        help='ä¸å¼ºåˆ¶åŠ è½½ç¤ºä¾‹CAPLä»£ç '
    )
    
    # ç»Ÿè®¡å’Œæ‘˜è¦
    parser.add_argument(
        '--show-summary',
        action='store_true',
        default=True,
        help='æ˜¾ç¤ºç”Ÿæˆæ‘˜è¦ (é»˜è®¤: å¼€å¯)'
    )
    
    parser.add_argument(
        '--hide-summary',
        action='store_false',
        dest='show_summary',
        help='éšè—ç”Ÿæˆæ‘˜è¦'
    )
    
    # æµå¼è¾“å‡ºæ§åˆ¶
    parser.add_argument(
        '--no-stream',
        action='store_true',
        help='ç¦ç”¨æµå¼è¾“å‡ºï¼Œä½¿ç”¨ä¼ ç»Ÿé˜»å¡å¼ç”Ÿæˆ'
    )
    
    # ä¿¡æ¯æŸ¥è¯¢
    parser.add_argument(
        '--info',
        action='store_true',
        help='æ˜¾ç¤ºçŸ¥è¯†åº“ä¿¡æ¯'
    )
    
    parser.add_argument(
        '--search',
        type=str,
        metavar='QUERY',
        help='æœç´¢çŸ¥è¯†åº“å†…å®¹'
    )
    
    parser.add_argument(
        '--count-tokens',
        action='store_true',
        help='è®¡ç®—è¾“å…¥éœ€æ±‚çš„tokenæ•°é‡ï¼ˆåŒ…æ‹¬promptæ¨¡æ¿å’ŒRAGä¸Šä¸‹æ–‡ï¼‰'
    )
    
    return parser


def load_config(args) -> CAPLGeneratorConfig:
    """æ ¹æ®å‘½ä»¤è¡Œå‚æ•°åŠ è½½é…ç½®"""
    config = CAPLGeneratorConfig()
    
    # åº”ç”¨å‘½ä»¤è¡Œå‚æ•°
    if args.disable_rag:
        config.enable_rag = False
    
    if args.k is not None:
        config.k = args.k
        
    if args.chunk_size is not None:
        config.chunk_size = args.chunk_size
        
    if args.chunk_overlap is not None:
        config.chunk_overlap = args.chunk_overlap
    
    if args.output:
        config.output_dir = Path(args.output)
    
    if args.api_type:
        config.api_type = args.api_type
    
    if args.api_url:
        config.api_base = args.api_url
    
    if args.model:
        config.model_name = args.model
    
    if args.use_example_code is not None:
        config.use_example_code = args.use_example_code
    
    return config

def load_requirements(input_source: str) -> str:
    """åŠ è½½éœ€æ±‚å†…å®¹"""
    if not input_source:
        return ""
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡ä»¶è·¯å¾„
    input_path = Path(input_source)
    if input_path.exists():
        with open(input_path, 'r', encoding='utf-8') as f:
            return f.read().strip()
    else:
        # ç›´æ¥ä½œä¸ºéœ€æ±‚æ–‡æœ¬
        return input_source.strip()

def show_knowledge_base_info(config: CAPLGeneratorConfig):
    """æ˜¾ç¤ºçŸ¥è¯†åº“ä¿¡æ¯"""
    from ..generator import CAPLGenerator
    generator = CAPLGenerator(config)
    
    info = generator.get_knowledge_base_info()
    print("\nğŸ“Š çŸ¥è¯†åº“ä¿¡æ¯:")
    print(f"   å¯ç”¨çŠ¶æ€: {'âœ…' if info['enabled'] else 'âŒ'}")
    print(f"   çŸ¥è¯†åº“ç›®å½•: {info['knowledge_base_dir']}")
    print(f"   å‘é‡æ•°æ®åº“ç›®å½•: {info['vector_db_dir']}")
    print(f"   å·²åŠ è½½æ–‡æ¡£: {info['documents_loaded']} ä¸ª")

def search_knowledge_base(config: CAPLGeneratorConfig, query: str):
    """æœç´¢çŸ¥è¯†åº“"""
    from ..generator import CAPLGenerator
    generator = CAPLGenerator(config)
    
    if not config.enable_rag:
        print("âŒ é”™è¯¯: æœç´¢åŠŸèƒ½éœ€è¦å¯ç”¨RAG")
        return
    
    results = generator.search_knowledge_base(query)
    if results:
        print(f"\nğŸ” æœç´¢ç»“æœ: æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³æ–‡æ¡£")
        for i, result in enumerate(results, 1):
            print(f"\n{i}. ğŸ“„ {result['source']} ({result['length']} å­—ç¬¦)")
            print(f"   æ‘˜è¦: {result['summary']}")
    else:
        print("ğŸ” æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£")

def main():
    """ä¸»å‡½æ•°"""
    parser = create_parser()
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥å‚æ•°
    if not args.input and not args.info and not args.search and not args.test_rag:
        parser.error("the following arguments are required: input (or use --info/--search/--test-rag)")
    
    try:
        # åŠ è½½é…ç½®
        config = load_config(args)
        
        # ä¿¡æ¯æŸ¥è¯¢æ¨¡å¼
        if args.info:
            show_knowledge_base_info(config)
            return
        
        if args.search:
            search_knowledge_base(config, args.search)
            return
            
        # Tokenè®¡æ•°æ¨¡å¼
        if args.count_tokens:
            if not args.input:
                print("âŒ é”™è¯¯: --count-tokens éœ€è¦æŒ‡å®šè¾“å…¥æ–‡ä»¶")
                return 1
            
            requirement = load_requirements(args.input)
            
            from ..services.generator_service import CAPLGeneratorService
            service = CAPLGeneratorService(config)
            
            print("ğŸ“Š è®¡ç®—prompt tokenæ•°é‡...")
            tokens_info = service.calculate_prompt_tokens(requirement)
            
            print(f"\nğŸ“‹ Tokenç»Ÿè®¡:")
            print(f"   ç³»ç»Ÿæç¤ºè¯: {tokens_info['system_prompt_tokens']} tokens ({tokens_info['system_prompt_length']} å­—ç¬¦)")
            print(f"   éœ€æ±‚å†…å®¹: {tokens_info['requirement_tokens']} tokens ({tokens_info['requirement_length']} å­—ç¬¦)")
            print(f"   åŸºç¡€prompt: {tokens_info['base_prompt_tokens']} tokens ({tokens_info['base_prompt_length']} å­—ç¬¦)")
            
            if config.enable_rag:
                print(f"   RAGä¸Šä¸‹æ–‡: {tokens_info['rag_context_tokens']} tokens ({tokens_info['rag_context_length']} å­—ç¬¦)")
                print(f"   æ€»prompt: {tokens_info['total_prompt_tokens']} tokens ({tokens_info['total_prompt_length']} å­—ç¬¦)")
            else:
                print(f"   æ€»prompt: {tokens_info['base_prompt_tokens']} tokens (RAGæœªå¯ç”¨)")
            
            return
        
        # ä½¿ç”¨é«˜çº§æœåŠ¡
        from ..services.generator_service import CAPLGeneratorService
        service = CAPLGeneratorService(config)

        # æµ‹è¯•RAGæœç´¢
        if args.test_rag:
            service.test_rag_search(args.test_rag, show_summary=True)
            return

        # é‡å»ºRAGçŸ¥è¯†åº“
        if args.rebuild_rag:
            service.process_file("dummy", rebuild_rag=True)
            return
        
        # å¤„ç†è¾“å…¥
        requirement = load_requirements(args.input)
        
        # ç”ŸæˆCAPLä»£ç 
        print(f"ğŸš€ å¼€å§‹ç”ŸæˆCAPLä»£ç ...")
        result = service.process_file(
            file_path=args.input,
            debug_prompt=args.debug_prompt,
            rebuild_rag=args.rebuild_rag,
            show_summary=args.show_summary,
            stream=not args.no_stream  # é»˜è®¤å¯ç”¨æµå¼è¾“å‡ºï¼Œé™¤éæŒ‡å®š--no-stream
        )
        
        if result["status"] == "success":
            print(f"âœ… ç”Ÿæˆå®Œæˆï¼")
            print(f"ğŸ“ Markdownæ–‡ä»¶: {result['file_path']}")
            print(f"ğŸ“ CAPLæ–‡ä»¶: {result['capl_file']}")
            
            if args.show_summary and result["stats"]:
                stats = result["stats"]
                print(f"\nğŸ“Š ç”Ÿæˆç»Ÿè®¡:")
                print(f"   ç”¨æ—¶: {stats['generation_time']} ç§’")
                print(f"   ä»£ç é•¿åº¦: {stats['code_length']} å­—ç¬¦")
                print(f"   ä»£ç è¡Œæ•°: {stats['code_lines']} è¡Œ")
                print(f"   ä¼°è®¡Token: {stats['estimated_tokens']}")
                print(f"   Tokené€Ÿç‡: {stats['token_rate']} tokens/ç§’")
        else:
            print(f"âŒ ç”Ÿæˆå¤±è´¥: {result['error']}")
            return 1
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­")
        return 0
    except Exception as e:
        print(f"âŒ é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0