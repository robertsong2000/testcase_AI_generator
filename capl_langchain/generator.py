"""åŸºäºLangChainçš„CAPLä»£ç ç”Ÿæˆå™¨"""

import os
import re
from pathlib import Path
from typing import Optional, Dict, Any, List

from langchain_core.prompts import ChatPromptTemplate, PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableSequence, RunnablePassthrough
from langchain.chains import RetrievalQA

from .config.config import CAPLGeneratorConfig
from .factories.llm_factory import LLMFactory
from .managers.prompt_manager import PromptTemplateManager
from .managers.knowledge_manager import KnowledgeBaseManager


class CAPLGenerator:
    """åŸºäºLangChainçš„CAPLä»£ç ç”Ÿæˆå™¨"""
    
    def __init__(self, config: Optional[CAPLGeneratorConfig] = None):
        self.config = config or CAPLGeneratorConfig()
        self.prompt_manager = PromptTemplateManager(self.config)
        self.kb_manager = KnowledgeBaseManager(self.config)
        self.llm = LLMFactory.create_llm(self.config)
        self.chain = None
        
    def initialize(self):
        """åˆå§‹åŒ–ç”Ÿæˆå™¨"""
        # åˆå§‹åŒ–çŸ¥è¯†åº“ï¼ˆå¦‚æœå¯ç”¨RAGï¼‰
        if self.config.enable_rag:
            self.kb_manager.initialize_knowledge_base()
        
        # æ„å»ºå¤„ç†é“¾
        self._build_chain()
    
    # æ„å»ºLangChainå¤„ç†é“¾
    def _build_chain(self):
        """æ„å»ºLangChainå¤„ç†é“¾"""
        if self.config.enable_rag and self.kb_manager.get_retriever():
            # RAGæ¨¡å¼
            retriever = self.kb_manager.get_retriever(self.config.k)
            
            prompt = ChatPromptTemplate.from_messages([
                ("system", self.prompt_manager.system_prompt),
                ("human", """
                åŸºäºä»¥ä¸‹çŸ¥è¯†åº“å†…å®¹ç”ŸæˆCAPLä»£ç ï¼š
                
                ç›¸å…³ä¸Šä¸‹æ–‡ï¼š
                {context}
                
                æµ‹è¯•éœ€æ±‚ï¼š
                {requirement}
                """)
            ])
            
            def format_docs(docs):
                return "\n\n".join(str(doc.page_content) for doc in docs)
            
            # ä¿®å¤ï¼šç¡®ä¿è¾“å…¥æ ¼å¼æ­£ç¡®ï¼Œå¹¶æ˜¾ç¤ºæ£€ç´¢ä¿¡æ¯
            def create_chain_input(requirement_str):
                # ç¡®ä¿requirementæ˜¯å­—ç¬¦ä¸²
                if isinstance(requirement_str, dict):
                    requirement_str = str(requirement_str.get('requirement', str(requirement_str)))
                elif not isinstance(requirement_str, str):
                    requirement_str = str(requirement_str)
                
                # è·å–ç›¸å…³æ–‡æ¡£å¹¶æ˜¾ç¤ºæ£€ç´¢ä¿¡æ¯
                print(f"\nğŸ” æ­£åœ¨æ£€ç´¢çŸ¥è¯†åº“...")
                docs = retriever.invoke(requirement_str)
                
                if docs:
                    print(f"âœ… æ£€ç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(docs)} ä¸ªç›¸å…³æ–‡æ¡£")
                    
                    # æ˜¾ç¤ºæ¯ä¸ªæ–‡æ¡£çš„ä¿¡æ¯
                    for i, doc in enumerate(docs, 1):
                        # è·å–æ–‡æ¡£æ¥æº
                        metadata = doc.metadata if hasattr(doc, 'metadata') else {}
                        source = metadata.get('source', 'æœªçŸ¥æ¥æº')
                        
                        # è·å–ç›¸å¯¹è·¯å¾„
                        try:
                            if source != 'æœªçŸ¥æ¥æº':
                                source_path = Path(source)
                                if source_path.is_absolute():
                                    try:
                                        source = str(source_path.relative_to(self.config.knowledge_base_dir))
                                    except ValueError:
                                        source = source_path.name
                                else:
                                    source = str(source_path)
                        except Exception:
                            source = str(source)
                        
                        # å†…å®¹æ‘˜è¦
                        content = doc.page_content if hasattr(doc, 'page_content') else str(doc)
                        summary = content[:100] + "..." if len(content) > 100 else content
                        
                        print(f"  ğŸ“„ æ–‡æ¡£ {i}: {source} ({len(content)} å­—ç¬¦)")
                        print(f"     æ‘˜è¦: {summary}")
                else:
                    print("âš ï¸  æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£ï¼Œå°†ä½¿ç”¨é€šç”¨æ¨¡æ¿")
                
                return {
                    "context": format_docs(docs),
                    "requirement": requirement_str
                }
            
            # æ„å»ºå®Œæ•´çš„å¤„ç†é“¾
            self.chain = RunnableSequence(
                create_chain_input,
                prompt,
                self.llm,
                StrOutputParser()
            )
            
        else:
            # éRAGæ¨¡å¼
            prompt = ChatPromptTemplate.from_messages([
                ("system", self.prompt_manager.system_prompt),
                ("human", "{requirement}")
            ])
            
            self.chain = RunnableSequence(
                prompt,
                self.llm,
                StrOutputParser()
            )
    
    def generate_code(self, requirement: str, output_file: Optional[str] = None) -> str:
        """ç”ŸæˆCAPLä»£ç ï¼ˆé˜»å¡å¼ï¼Œä¿æŒå‘åå…¼å®¹ï¼‰"""
        try:
            if self.chain is None:
                self.initialize()
            
            print(f"\nğŸ¤– æ­£åœ¨ç”ŸæˆCAPLä»£ç ...")
            print(f"ğŸ“‹ éœ€æ±‚: {requirement[:100]}...")
            
            # ç”Ÿæˆä»£ç 
            generated_code = self.chain.invoke(requirement)
            
            # æ¸…ç†ç”Ÿæˆçš„ä»£ç 
            cleaned_code = self._clean_generated_code(generated_code)
            
            # ä¸å†ä¿å­˜åˆ°ä¸­é—´æ–‡ä»¶ï¼Œç›´æ¥è¿”å›ç”Ÿæˆçš„ä»£ç 
            print(f"âœ… ä»£ç ç”Ÿæˆå®Œæˆï¼")
            
            return cleaned_code
            
        except Exception as e:
            print(f"âŒ ä»£ç ç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return f"// ä»£ç ç”Ÿæˆå¤±è´¥: {str(e)}"
    
    def generate_code_stream(self, requirement: str, output_file: Optional[str] = None):
        """æµå¼ç”ŸæˆCAPLä»£ç 
        
        è¿™æ˜¯ä¸€ä¸ªç”Ÿæˆå™¨å‡½æ•°ï¼Œå¯ä»¥å®æ—¶è¾“å‡ºç”Ÿæˆçš„ä»£ç å†…å®¹ã€‚
        ä½¿ç”¨ç¤ºä¾‹ï¼š
            generator = CAPLGenerator(config)
            for chunk in generator.generate_code_stream("æµ‹è¯•éœ€æ±‚"):
                print(chunk, end='', flush=True)
        
        Args:
            requirement: éœ€æ±‚æè¿°
            output_file: å¯é€‰çš„è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Yields:
            str: ç”Ÿæˆçš„ä»£ç ç‰‡æ®µ
        """
        try:
            if self.chain is None:
                self.initialize()
            
            print(f"\nğŸ¤– å¼€å§‹æµå¼ç”ŸæˆCAPLä»£ç ...")
            print(f"ğŸ“‹ éœ€æ±‚: {requirement[:100]}...")
            
            # ä½¿ç”¨æµå¼è¾“å‡º
            if hasattr(self.llm, 'stream'):
                # ç¡®ä¿åˆå§‹åŒ–
                if self.chain is None:
                    self.initialize()
                
                # æ˜¾ç¤ºæ£€ç´¢ä¿¡æ¯ï¼ˆä¸éæµå¼æ¨¡å¼ä¸€è‡´ï¼‰
                if self.config.enable_rag and self.kb_manager.get_retriever():
                    retriever = self.kb_manager.get_retriever(self.config.k)
                    docs = retriever.invoke(requirement)
                    
                    if docs:
                        print(f"âœ… æ£€ç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(docs)} ä¸ªç›¸å…³æ–‡æ¡£")
                        for i, doc in enumerate(docs, 1):
                            metadata = doc.metadata if hasattr(doc, 'metadata') else {}
                            source = metadata.get('source', 'æœªçŸ¥æ¥æº')
                            content = doc.page_content if hasattr(doc, 'page_content') else str(doc)
                            print(f"  ğŸ“„ æ–‡æ¡£ {i}: {source} ({len(content)} å­—ç¬¦)")
                            print(f"     æ‘˜è¦: {content[:100]}{'...' if len(content) > 100 else ''}")
                    else:
                        print("âš ï¸  æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£ï¼Œå°†ä½¿ç”¨é€šç”¨æ¨¡æ¿")
                
                print(f"â³ æ­£åœ¨ç”Ÿæˆä¸­...")
                
                # ä½¿ç”¨å®Œæ•´çš„LangChainå¤„ç†é“¾è¿›è¡Œæµå¼ç”Ÿæˆ
                full_code = ""
                for chunk in self.chain.stream(requirement):
                    if chunk:
                        content = str(chunk)
                        full_code += content
                        yield content
                
                # æ¸…ç†æœ€ç»ˆä»£ç 
                cleaned_code = self._clean_generated_code(full_code)
                if cleaned_code != full_code:
                    yield "\n" + cleaned_code[len(full_code):] if len(cleaned_code) > len(full_code) else ""
                
            else:
                # å›é€€åˆ°é˜»å¡å¼ç”Ÿæˆ
                print("âš ï¸  å½“å‰LLMä¸æ”¯æŒæµå¼è¾“å‡ºï¼Œä½¿ç”¨é˜»å¡å¼ç”Ÿæˆ...")
                code = self.generate_code(requirement, output_file)
                yield code
                
        except Exception as e:
            error_msg = f"// ä»£ç ç”Ÿæˆå¤±è´¥: {str(e)}"
            yield error_msg
            print(f"âŒ ä»£ç ç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    def _clean_generated_code(self, code: str) -> str:
        """æ¸…ç†ç”Ÿæˆçš„ä»£ç """
        # ç§»é™¤å¯èƒ½çš„markdownä»£ç å—æ ‡è®°
        code = re.sub(r'^```capl\n', '', code)
        code = re.sub(r'^```\n', '', code)
        code = re.sub(r'\n```$', '', code)
        
        # ç§»é™¤è¡Œå°¾çš„ç©ºç™½å­—ç¬¦
        lines = code.split('\n')
        cleaned_lines = [line.rstrip() for line in lines]
        
        # ç§»é™¤å¤šä½™çš„ç©ºè¡Œ
        while cleaned_lines and not cleaned_lines[0].strip():
            cleaned_lines.pop(0)
        while cleaned_lines and not cleaned_lines[-1].strip():
            cleaned_lines.pop()
        
        return '\n'.join(cleaned_lines)
    
    def get_knowledge_base_info(self) -> Dict[str, Any]:
        """è·å–çŸ¥è¯†åº“ä¿¡æ¯"""
        info = {
            'enabled': self.config.enable_rag,
            'knowledge_base_dir': str(self.config.knowledge_base_dir),
            'vector_db_dir': str(self.config.vector_db_dir),
            'documents_loaded': 0,
            'search_results': []
        }
        
        if self.config.enable_rag and self.config.knowledge_base_dir.exists():
            # è·å–æ–‡æ¡£æ•°é‡
            documents = []
            for pattern in ["**/*.txt", "**/*.md", "**/*.capl", "**/*.py"]:
                documents.extend(list(self.config.knowledge_base_dir.glob(pattern)))
            info['documents_loaded'] = len(documents)
        
        return info
    
    def search_knowledge_base(self, query: str, k: int = 4) -> List[Dict[str, Any]]:
        """æœç´¢çŸ¥è¯†åº“"""
        if not self.config.enable_rag:
            return []
        
        return self.kb_manager.search_documents(query, k)